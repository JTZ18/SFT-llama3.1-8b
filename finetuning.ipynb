{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6abd8ae-3add-49a0-9dac-8021b408825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging, TextStreamer, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "import os, torch, wandb, platform, warnings\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from huggingface_hub import notebook_login\n",
    "from typing import List, Union, Any, Dict\n",
    "import json\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da4a1a0-0ca8-4258-8269-0de116a1bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(path: str):\n",
    "    with open(path, \"r\") as f:\n",
    "        sessions = json.load(f)\n",
    "\n",
    "    final_sessions = []\n",
    "    for session in sessions:\n",
    "        session_str = \"\\n\".join([f\"<|im_start|>{msg['author']}\\n{msg['text']}<|im_end|>\" for msg in session])\n",
    "        final_sessions.append(session_str)\n",
    "\n",
    "    return final_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a3e3f7-3d03-4ca5-8010-2b0e04704f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollatorForLanguageModelingChatML(DataCollatorForLanguageModeling):\n",
    "    \"\"\"\n",
    "    Data collator for [ChatML](https://github.com/openai/openai-python/blob/main/chatml.md) format, like:\n",
    "    ```\n",
    "    <|im_start|>Alexander Smirnov\n",
    "    >>> здарова нормик<|im_end|>\n",
    "    <|im_start|>Федук\n",
    "    >>> чо ты куда пропал то<|im_end|>\n",
    "    <|im_start|>Alexander Smirnov\n",
    "    >>> вечером сделаю бота\n",
    "    >>> сегодня еще дедлайн по домке<|im_end|>\n",
    "    ```\n",
    "    Reference data collator implementation: [DataCollatorForCompletionOnlyLM](https://github.com/huggingface/trl/blob/main/trl/trainer/utils.py#L56)\n",
    "    \n",
    "    Args:\n",
    "        mlm (`bool`, *optional*, defaults to `False`): Whether or not to use masked language modeling in the underlying\n",
    "            `DataCollatorForLanguageModeling` class. Note that this option currently has no effect but is present\n",
    "             for flexibility and backwards-compatibility.\n",
    "        ignore_index (`int`, *optional*, defaults to `-100`):\n",
    "            The index to use to ignore the initial tokens with\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        mlm: bool = False,\n",
    "        ignore_index: int = -100,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, mlm=mlm, **kwargs)\n",
    "        self.ignore_index = ignore_index\n",
    "        self.start_token = self.tokenizer.encode(\"<|im_start|>\", add_special_tokens=False)[0]\n",
    "        self.end_token = self.tokenizer.encode(\"<|im_end|>\", add_special_tokens=False)[0]\n",
    "        self.new_line_token = self.tokenizer.encode(\"\\n\", add_special_tokens=False)[-1]\n",
    "        self.bos_token = self.tokenizer.bos_token_id\n",
    "\n",
    "        print(self.start_token)\n",
    "        print(self.end_token)\n",
    "        print(self.new_line_token)\n",
    "\n",
    "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
    "        batch = super().torch_call(examples)\n",
    "\n",
    "        for i in range(len(examples)):\n",
    "            if_start = False\n",
    "            for j in range(len(batch[\"labels\"][i])):\n",
    "\n",
    "                token = batch[\"labels\"][i][j].item()\n",
    "                \n",
    "                if token == self.start_token:\n",
    "                    if_start = True\n",
    "\n",
    "                if if_start or token == self.bos_token:\n",
    "                    batch[\"labels\"][i][j] = self.ignore_index\n",
    "                    \n",
    "                if token == self.new_line_token:\n",
    "                    if_start = False\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10820225-1a85-4e14-addf-9201c5972e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32001\n",
      "32000\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "base_model = \"ehartford/dolphin-2.2.1-mistral-7b\" #someone13574/Mistral-7B-v0.1-sharded\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "dataset = Dataset.from_dict({\"session\": prepare_dataset(\"./data/messages.json\")})\n",
    "\n",
    "data_collator = DataCollatorForLanguageModelingChatML(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56886018-d37b-43a7-82fb-6d74468f4135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>Alexander Smirnov\n",
      ">>> здарова нормик<|im_end|>\n",
      "<|im_start|>Федук\n",
      ">>> чо ты куда пропал то<|im_end|>\n",
      "<|im_start|>Alexander Smirnov\n",
      ">>> вечером сделаю бота\n",
      ">>> сегодня еще дедлайн по домке<|im_end|>\n",
      "<|im_start|>Федук\n",
      ">>> ок, на один глаз залетишь на умник?<|im_end|>\n",
      "<|im_start|>Alexander Smirnov\n",
      ">>> на наш залечу<|im_end|>\n",
      "<|im_start|>Федук\n",
      ">>> кк<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[2500][\"session\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f417431d-8824-474a-995e-6444aabdc759",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator_res = data_collator([tokenizer(dataset[\"session\"][2500], return_tensors=\"pt\")[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb569c8c-719e-479c-9072-4b17ef15836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> здарова нормик<|im_end|> \n",
      ">>> чо ты куда пропал то<|im_end|> \n",
      ">>> вечером сделаю бота\n",
      ">>> сегодня еще дедлайн по домке<|im_end|> \n",
      ">>> ок, на один глаз залетишь на умник?<|im_end|> \n",
      ">>> на наш залечу<|im_end|> \n",
      ">>> кк<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(collator_res[\"labels\"][0][collator_res[\"labels\"][0] != -100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ac13329-f547-4331-bb5a-0c8d228d27d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd7fc0682ed4af68b3e3bc469686279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit= True,\n",
    "    bnb_4bit_quant_type= \"nf4\",\n",
    "    bnb_4bit_compute_dtype= torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant= False,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    base_model,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map={\"\": 0}\n",
    ")\n",
    "model.config.use_cache = False # silence the warnings. Please re-enable for inference!\n",
    "model.config.pretraining_tp = 1\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f9a82af-72ab-4890-9c36-914abc5f2b8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfuriousteabag\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.12"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/admin/doppelganger/wandb/run-20231101_165524-f1gwmcew</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/furiousteabag/Fine%20tuning%20mistral%207B/runs/f1gwmcew' target=\"_blank\">true-dew-2</a></strong> to <a href='https://wandb.ai/furiousteabag/Fine%20tuning%20mistral%207B' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/furiousteabag/Fine%20tuning%20mistral%207B' target=\"_blank\">https://wandb.ai/furiousteabag/Fine%20tuning%20mistral%207B</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/furiousteabag/Fine%20tuning%20mistral%207B/runs/f1gwmcew' target=\"_blank\">https://wandb.ai/furiousteabag/Fine%20tuning%20mistral%207B/runs/f1gwmcew</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/furiousteabag/Fine%20tuning%20mistral%207B/runs/f1gwmcew?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f3b67c038e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3b6df0fb20>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3b6d68e830, execution_count=9 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3b6d68e6e0, raw_cell=\"wandb.init(project='Fine tuning mistral 7B', job_t..\" store_history=True silent=False shell_futures=True cell_id=6f9a82af-72ab-4890-9c36-914abc5f2b8e> result=<wandb.sdk.wandb_run.Run object at 0x7f3b67c038e0>>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "wandb.init(project='Fine tuning mistral 7B', job_type=\"training\", anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9db352f3-3ddb-4678-b896-12a8d21dc3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3b6df0fb20>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3b67ce4eb0, raw_cell=\"model = prepare_model_for_kbit_training(model)\n",
      "pef..\" store_history=True silent=False shell_futures=True cell_id=9db352f3-3ddb-4678-b896-12a8d21dc3e2>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3b6df0fb20>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3b67ce48b0, execution_count=10 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3b67ce4eb0, raw_cell=\"model = prepare_model_for_kbit_training(model)\n",
      "pef..\" store_history=True silent=False shell_futures=True cell_id=9db352f3-3ddb-4678-b896-12a8d21dc3e2> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "model = prepare_model_for_kbit_training(model)\n",
    "peft_config = LoraConfig(\n",
    "        r=16,\n",
    "        lora_alpha=16,\n",
    "        lora_dropout=0.05,\n",
    "        bias=\"none\",\n",
    "        task_type=\"CAUSAL_LM\",\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\"gate_proj\"]\n",
    "    )\n",
    "model = get_peft_model(model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4da5949-7786-4c11-b679-9a6305cfc56e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3b6df0fb20>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3b67ce45b0, raw_cell=\"training_arguments = TrainingArguments(\n",
      "    output..\" store_history=True silent=False shell_futures=True cell_id=e4da5949-7786-4c11-b679-9a6305cfc56e>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/share/anaconda3/envs/doppelganger/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:173: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8c54735e0445e68d395f2208763e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7982 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3b6df0fb20>> (for post_run_cell), with arguments args (<ExecutionResult object at 7f3b67ce45e0, execution_count=11 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7f3b67ce45b0, raw_cell=\"training_arguments = TrainingArguments(\n",
      "    output..\" store_history=True silent=False shell_futures=True cell_id=e4da5949-7786-4c11-b679-9a6305cfc56e> result=None>,),kwargs {}:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/admin/.local/share/anaconda3/envs/doppelganger/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:214: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._pause_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._pause_backend() takes 1 positional argument but 2 were given"
     ]
    }
   ],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir= \"./results\",\n",
    "    num_train_epochs= 3,\n",
    "    per_device_train_batch_size= 2,\n",
    "    gradient_accumulation_steps= 8,\n",
    "    optim = \"paged_adamw_8bit\",\n",
    "    save_steps= 5000,\n",
    "    logging_steps= 30,\n",
    "    learning_rate= 2e-4,\n",
    "    weight_decay= 0.001,\n",
    "    fp16= False,\n",
    "    bf16= False,\n",
    "    max_grad_norm= 0.3,\n",
    "    max_steps= -1,\n",
    "    warmup_ratio= 0.3,\n",
    "    group_by_length= True,\n",
    "    lr_scheduler_type= \"constant\",\n",
    "    report_to=\"wandb\"\n",
    ")\n",
    "# Setting sft parameters\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset,\n",
    "    peft_config=peft_config,\n",
    "    max_seq_length= None,\n",
    "    dataset_text_field=\"session\",\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_arguments,\n",
    "    packing= False,\n",
    "    data_collator=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c8ccaa-fa36-4977-95e1-55b63fe49094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._resume_backend of <wandb.sdk.wandb_init._WandbInit object at 0x7f3b6df0fb20>> (for pre_run_cell), with arguments args (<ExecutionInfo object at 7f3b67ce4bb0, raw_cell=\"trainer.train()\n",
      "# Save the fine-tuned model\n",
      "traine..\" store_history=True silent=False shell_futures=True cell_id=e3c8ccaa-fa36-4977-95e1-55b63fe49094>,),kwargs {}:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_WandbInit._resume_backend() takes 1 positional argument but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: _WandbInit._resume_backend() takes 1 positional argument but 2 were given"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "/home/admin/.local/share/anaconda3/envs/doppelganger/lib/python3.10/site-packages/torch/utils/checkpoint.py:429: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4' max='1494' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [   4/1494 06:28 < 80:17:54, 0.01 it/s, Epoch 0.01/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.train()\n",
    "# Save the fine-tuned model\n",
    "trainer.model.save_pretrained(\"finetuned-7b-telegram\")\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec59cf8-e1f4-44c0-8c12-21cb142b4b85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
