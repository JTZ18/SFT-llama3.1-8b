{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6abd8ae-3add-49a0-9dac-8021b408825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig,HfArgumentParser,TrainingArguments,pipeline, logging, TextStreamer, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, PeftModel, prepare_model_for_kbit_training, get_peft_model\n",
    "import os, torch, wandb, platform, warnings\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "from huggingface_hub import notebook_login\n",
    "from typing import List, Union, Any, Dict\n",
    "import json\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3da4a1a0-0ca8-4258-8269-0de116a1bb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(path: str):\n",
    "    with open(path, \"r\") as f:\n",
    "        sessions = json.load(f)\n",
    "\n",
    "    final_sessions = []\n",
    "    for session in sessions:\n",
    "        session_str = \"\\n\".join([f\"<|im_start|>{msg['author']}\\n{msg['text']}<|im_end|>\" for msg in session])\n",
    "        final_sessions.append(session_str)\n",
    "\n",
    "    return final_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4a3e3f7-3d03-4ca5-8010-2b0e04704f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataCollatorForLanguageModelingChatML(DataCollatorForLanguageModeling):\n",
    "    \"\"\"\n",
    "    Data collator for [ChatML](https://github.com/openai/openai-python/blob/main/chatml.md) format, like:\n",
    "    ```\n",
    "    <|im_start|>Alexander Smirnov\n",
    "    >>> здарова нормик<|im_end|>\n",
    "    <|im_start|>Федук\n",
    "    >>> чо ты куда пропал то<|im_end|>\n",
    "    <|im_start|>Alexander Smirnov\n",
    "    >>> вечером сделаю бота\n",
    "    >>> сегодня еще дедлайн по домке<|im_end|>\n",
    "    ```\n",
    "    Reference data collator implementation: [DataCollatorForCompletionOnlyLM](https://github.com/huggingface/trl/blob/main/trl/trainer/utils.py#L56)\n",
    "    \n",
    "    Args:\n",
    "        mlm (`bool`, *optional*, defaults to `False`): Whether or not to use masked language modeling in the underlying\n",
    "            `DataCollatorForLanguageModeling` class. Note that this option currently has no effect but is present\n",
    "             for flexibility and backwards-compatibility.\n",
    "        ignore_index (`int`, *optional*, defaults to `-100`):\n",
    "            The index to use to ignore the initial tokens with\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *args,\n",
    "        mlm: bool = False,\n",
    "        ignore_index: int = -100,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, mlm=mlm, **kwargs)\n",
    "        self.ignore_index = ignore_index\n",
    "        self.start_token = self.tokenizer.encode(\"<|im_start|>\", add_special_tokens=False)[0]\n",
    "        self.end_token = self.tokenizer.encode(\"<|im_end|>\", add_special_tokens=False)[0]\n",
    "        self.new_line_token = self.tokenizer.encode(\"\\n\", add_special_tokens=False)[-1]\n",
    "        self.bos_token = self.tokenizer.bos_token_id\n",
    "\n",
    "        print(self.start_token)\n",
    "        print(self.end_token)\n",
    "        print(self.new_line_token)\n",
    "\n",
    "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
    "        batch = super().torch_call(examples)\n",
    "\n",
    "        for i in range(len(examples)):\n",
    "            if_start = False\n",
    "            for j in range(len(batch[\"labels\"][i])):\n",
    "\n",
    "                token = batch[\"labels\"][i][j].item()\n",
    "                \n",
    "                if token == self.start_token:\n",
    "                    if_start = True\n",
    "\n",
    "                if if_start or token == self.end_token or token == self.bos_token:\n",
    "                    batch[\"labels\"][i][j] = self.ignore_index\n",
    "                    \n",
    "                if token == self.new_line_token:\n",
    "                    if_start = False\n",
    "\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10820225-1a85-4e14-addf-9201c5972e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32001\n",
      "32000\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "base_model = \"ehartford/dolphin-2.2.1-mistral-7b\" #someone13574/Mistral-7B-v0.1-sharded\n",
    "\n",
    "#model = AutoModelForCausalLM.from_pretrained(base_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "dataset = Dataset.from_dict({\"session\": prepare_dataset(\"./data/messages.json\")})\n",
    "\n",
    "data_collator = DataCollatorForLanguageModelingChatML(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56886018-d37b-43a7-82fb-6d74468f4135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>Alexander Smirnov\n",
      ">>> здарова нормик<|im_end|>\n",
      "<|im_start|>Федук\n",
      ">>> чо ты куда пропал то<|im_end|>\n",
      "<|im_start|>Alexander Smirnov\n",
      ">>> вечером сделаю бота\n",
      ">>> сегодня еще дедлайн по домке<|im_end|>\n",
      "<|im_start|>Федук\n",
      ">>> ок, на один глаз залетишь на умник?<|im_end|>\n",
      "<|im_start|>Alexander Smirnov\n",
      ">>> на наш залечу<|im_end|>\n",
      "<|im_start|>Федук\n",
      ">>> кк<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "print(dataset[2500][\"session\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f417431d-8824-474a-995e-6444aabdc759",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator_res = data_collator([tokenizer(dataset[\"session\"][2500], return_tensors=\"pt\")[\"input_ids\"][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb569c8c-719e-479c-9072-4b17ef15836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> здарова нормик \n",
      ">>> чо ты куда пропал то \n",
      ">>> вечером сделаю бота\n",
      ">>> сегодня еще дедлайн по домке \n",
      ">>> ок, на один глаз залетишь на умник? \n",
      ">>> на наш залечу \n",
      ">>> кк\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(collator_res[\"labels\"][0][collator_res[\"labels\"][0] != -100]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
